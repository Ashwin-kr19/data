# -*- coding: utf-8 -*-
"""pract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wk1QYELoi9kN6HR6wQufnRGpMNqqHARX

#**Preprocess**
"""

import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
import numpy as np

documents = open('/content/documents.txt')
content = documents.readlines()
print(content[:5])

paragraphs = []
temp = ""
for i in content:
  if i == "\n":
    paragraphs.append(temp)
    temp = ""
  else:
    temp += i

paragraphs[:4]

def preprocess(text):
  text = re.sub('[^A-Za-z0-9]+ ', '',text)
  text = text.lower()
  text = text.replace("\n", " ")
  text = text.replace("\ufeff", "")
  return text

preprocessed_paragraphs = []
for i in paragraphs:
  preprocessed_paragraphs.append(preprocess(i))
preprocessed_paragraphs[:5]

"""#**Boolean**"""

keywords = open("/content/keywords.txt")
keywords = keywords.readlines()
keywords = [i.replace("\n", "") for i in keywords]
keywords[:5]

#inverted_index
inverted_index = {}
for keyword in keywords:
  inverted_index[keyword] = []

for keyword in keywords:
  for i in range(len(preprocessed_paragraphs)):
    if keyword in preprocessed_paragraphs[i]:
      inverted_index[keyword].append(i)
print(inverted_index)

vectorizer = CountVectorizer()
binary_bow = vectorizer.fit_transform(preprocessed_paragraphs)
binary_bow_values = binary_bow.toarray()
feature_bow = list(vectorizer.get_feature_names_out())

df_bow = pd.DataFrame(binary_bow_values, columns = feature_bow)

#df_bow = pd.DataFrame(binary_bow_values, columns = feature_bow)
df_bow[:2]

#query
#Binary Query using And Or
query = "reasoning AND home OR group"
words = query.split()
res_df = None
character = 0
while character < len(words):

  if words[character]=="OR":
    res_df = res_df | df_bow[words[character+1]]
    character += 2
  elif words[character]=="AND":
    res_df = res_df & df_bow[words[character+1]]
    character += 2
  else:
    res_df = df_bow[words[character]]
    character += 1

res_df = list(res_df)

#List of documents satisfying the given query
documents_index = []
for i in range(len(res_df)):
  if res_df[i]>0:
    documents_index.append(i)
  else:
    continue
print("Satisfied Results Document Index:",documents_index)
print("Query:",query)
print("Results:")
for i in range(len(documents_index[:5])):
  print("TOP ",i+1,":",paragraphs[documents_index[i]])

"""#Vector

"""

#ranked
def cosine_sim(v1,v2):
  return np.dot(v1,v2)/(np.linalg.norm(v1) * np.linalg.norm(v2))

def retriver(content,query,top_k):
  result = {}
  for i in range(len(content)):
    result[i] = cosine_sim(content[i], query)
  result = {k: v for k,v in sorted(result.items(), key = lambda item: item[1], reverse = True)}
  return list(result.keys())[:top_k]

vectorizer = TfidfVectorizer()
tfidf_para = vectorizer.fit_transform(preprocessed_paragraphs).toarray()

query = ["international machine learning conference".lower()]
tfidf_query = list(vectorizer.transform(query).toarray()[0])
top_k = 5

results = retriver(tfidf_para,tfidf_query,top_k)
results

for i in range(len(results)):
  print("TOP",i+1,":",paragraphs[results[i]])

